---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

These projects show some of the applications of my work.

## Digital heritage 

The [SUMUM](https://anr-sumum.fr) project, funded by the French National Research Agency (ANR), aimed to develop strategies for the documentation, conservation, and restoration of cultural heritage.  

**L'Arbre aux Serpents**  

I was part of an [acquisition campaign](https://anr-sumum.fr/campagne-de-captation-dimages-de-larbre-aux-serpents-de-niki-de-saint-phalle-juillet-2018/) for L'Arbre aux Serpents, a sculpture by Niki de Saint Phalle, at the Musée des Beaux-Arts in Angers, France.  

Below is a 3D reconstruction (sparse point cloud) of the sculpture obtained using our autocalibration method from BMVC 2020, computed from around 50 images.  
<div style="display: flex; justify-content: center; align-items: center; height: 50vh;">
  <img src="/files/Figures/ArbreSerpents_BMVC20.png" alt="Result from EIP method" style="max-width: 50%; height: auto;">
</div>

## Digital healthcare

The [Endomapper](https://sites.google.com/unizar.es/endomapper/home) project, funded by the European Union's Horizon 2020 research and innovation program, aimed to advance the theory and practice of real-time localization and mapping within the human body, using only a standard monocular endoscope.  

**Internships**

I supervised two Master's students at the University of Clermont Auvergne during the project:  

- Youssef Ezidi (April-September 2024): developed a graphical user interface for point tracking in endoscopy images.
- Timothé Chavant-Duché (May-July 2024): worked on segmenting specular highlights in endoscopy images.


## Robot vision

Earlier work on computer vision for robotics from before my PhD.

**Package delivery with a camera drone**  

<iframe width="560" height="315" src="https://www.youtube.com/embed/bxM6dls2wuo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>    
  
This work was part of my internship at the [Institute of Computer Graphics and Vision](https://www.tugraz.at/institute/icg/home/), TU Graz, where I worked with [Friedrich Fraundorfer](https://www.tugraz.at/institute/icg/research/team-fraundorfer/people/friedrich-fraundorfer/) and his research group. This demo with an industrial partner showcased autonomous package delivery using a camera drone. It involved the following autonomously performed tasks: taking off from a stationary vehicle, navigating to the delivery site, landing and dropping the package, flying back to the distribution vehicle, following the vehicle as it moved, and finally landing when the vehicle was stationary. I worked on robust camera pose estimation and tag detection.  
  
[Paper](https://graz.elsevierpure.com/en/publications/package-delivery-experiments-with-a-camera-drone)


**Visual contact with cadioptric cameras**

<iframe src="https://drive.google.com/file/d/15TfjvueRHcyqLvz3zdAiU60KdjgFEIKi/preview" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>  
  
This work was from a two-month summer internship at the [MIS lab](https://www.mis.u-picardie.fr), University of Picardie Jules Verne, where I worked with [Cédric Demonceaux](https://sites.google.com/view/cedricdemonceaux/home) and [El Mustapha Mouaddib](https://home.mis.u-picardie.fr/~mouaddib/index.php?page=accueil) in the Robotic Perception group. The group specializes in omnidirectional vision and had published a method for time-to-contact estimation using a central catadioptric camera. In my internship, I implemented and tested this method using a Pioneer 3-AT mobile robot. The main tools used were ROS and OpenCV. I also showed example applications of the method, including depth computation and vision-based braking. More details and results in the slides (quality may be a bit poor due to conversion from PDF) and the report.  
  
[Report](/files/Publications/VisualContact_Report.pdf) <span style="display: inline-block; width: 10px;"></span> [Slides](https://docs.google.com/presentation/d/1c3bOevwVjbf8PJqQAFYKfqNDCrETQdBFC3qn7KOI7lY/edit?usp=sharing)  


**Explorator**  
  
<iframe width="560" height="315" src="https://www.youtube.com/embed/ZcCxXC5oHmk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>    

This was a fun robotics project that I did in my Master's program. More details in the report. 

[Report](/files/Publications/Explorator_Report.pdf)


